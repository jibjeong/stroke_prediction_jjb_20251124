# Stroke Prediction Using Machine Learning

ë‡Œì¡¸ì¤‘(Stroke) ë°œìƒ ìœ„í—˜ì„ ì˜ˆì¸¡í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. í¬ìŠ¤í„° ê¸°ë°˜ ë¶„ì„ì„ ì¬í˜„í•˜ì—¬ 7ê°€ì§€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.

## ğŸ“Š í”„ë¡œì íŠ¸ ê°œìš”

### ëª©ì 
í™˜ìì˜ ì„ìƒ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‡Œì¡¸ì¤‘ ë°œìƒ ìœ„í—˜ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ê°œë°œí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•
- **ë°ì´í„°**: 5,109ëª…ì˜ í™˜ì ë°ì´í„° (12ê°œ ë³€ìˆ˜)
- **ëª¨ë¸**: 7ê°€ì§€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë¹„êµ
- **í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬**: SMOTE ì ìš©
- **í‰ê°€**: í¬ìŠ¤í„° ê¸°ë°˜ Table 1, Table 2, Figure 3, Figure 4 ìƒì„±

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
stroke_prediction_jjb_20251124/
â”œâ”€â”€ dataset/                    # ì›ë³¸ ë°ì´í„°
â”‚   â””â”€â”€ stroke_dataset.csv     # 5,110 rows Ã— 12 columns
â”‚
â”œâ”€â”€ analysis_01_preprocess/     # Phase 1: ë°ì´í„° ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ 01_data_preprocessing.py
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ final/
â”‚           â”œâ”€â”€ stroke_preprocessed.csv
â”‚           â””â”€â”€ stroke_original.csv
â”‚
â”œâ”€â”€ analysis_02_eda/            # Phase 2: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ 01_eda_analysis.py
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ figures/           # íˆíŠ¸ë§µ, ë¶„í¬ ê·¸ë˜í”„
â”‚       â””â”€â”€ tables/            # í†µê³„ í…Œì´ë¸”
â”‚
â”œâ”€â”€ analysis_03_model/          # Phase 3: ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ baseline/
â”‚   â”‚   â”‚   â””â”€â”€ 01_train_models.py
â”‚   â”‚   â””â”€â”€ evaluation/
â”‚   â”‚       â”œâ”€â”€ 02_shap_analysis.py
â”‚   â”‚       â””â”€â”€ 03_additional_evaluation.py
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ tables/
â”‚       â”‚   â”œâ”€â”€ table1_average_performance.csv
â”‚       â”‚   â”œâ”€â”€ table2_class_performance.csv
â”‚       â”‚   â”œâ”€â”€ calibration_metrics.csv
â”‚       â”‚   â”œâ”€â”€ optimal_thresholds.csv
â”‚       â”‚   â””â”€â”€ comprehensive_evaluation.csv
â”‚       â”œâ”€â”€ figures/
â”‚       â”‚   â”œâ”€â”€ figure3_roc_curves_stroke_no.png
â”‚       â”‚   â”œâ”€â”€ figure4_roc_curves_stroke_yes.png
â”‚       â”‚   â”œâ”€â”€ confusion_matrices.png
â”‚       â”‚   â”œâ”€â”€ calibration_curves.png
â”‚       â”‚   â”œâ”€â”€ precision_recall_curves.png
â”‚       â”‚   â”œâ”€â”€ clinical_risk_stratification.png
â”‚       â”‚   â”œâ”€â”€ shap_importance_*.png (3 models)
â”‚       â”‚   â”œâ”€â”€ shap_summary_*.png (3 models)
â”‚       â”‚   â””â”€â”€ shap_dependence_*.png (3 models)
â”‚       â””â”€â”€ models/            # í•™ìŠµëœ ëª¨ë¸ (.pkl)
â”‚
â”œâ”€â”€ paper/                      # í•™ìˆ  ë…¼ë¬¸
â”‚   â”œâ”€â”€ sections/               # ë…¼ë¬¸ ì„¹ì…˜ë³„ íŒŒì¼
â”‚   â”‚   â”œâ”€â”€ 01_background.md
â”‚   â”‚   â”œâ”€â”€ 02_methods.md
â”‚   â”‚   â”œâ”€â”€ 03_results.md
â”‚   â”‚   â””â”€â”€ 04_conclusions.md
â”‚   â”œâ”€â”€ main_paper.md          # í†µí•© ë…¼ë¬¸ (14 figures)
â”‚   â”œâ”€â”€ figures/               # ë…¼ë¬¸ìš© figure (ìƒëŒ€ê²½ë¡œ ì°¸ì¡°)
â”‚   â””â”€â”€ tables/                # ë…¼ë¬¸ìš© table
â”‚
â”œâ”€â”€ utils/                      # ê³µí†µ ìœ í‹¸ë¦¬í‹°
â”‚   â””â”€â”€ config.py
â”‚
â”œâ”€â”€ run_full_pipeline.py        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ README.md                   # ë³¸ íŒŒì¼
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

#### í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install pandas numpy scikit-learn matplotlib seaborn xgboost imbalanced-learn shap
```

#### ë˜ëŠ” requirements.txt ì‚¬ìš©
```bash
pip install -r requirements.txt
```

### 2. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```bash
# ì „ì²´ íŒŒì´í”„ë¼ì¸ í•œ ë²ˆì— ì‹¤í–‰
python run_full_pipeline.py
```

### 3. ê°œë³„ Phase ì‹¤í–‰

```bash
# Phase 1: ë°ì´í„° ì „ì²˜ë¦¬
python analysis_01_preprocess/scripts/01_data_preprocessing.py

# Phase 2: EDA
python analysis_02_eda/scripts/01_eda_analysis.py

# Phase 3: ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
python analysis_03_model/scripts/baseline/01_train_models.py

# Phase 4: SHAP ë¶„ì„ (Feature Importance)
python analysis_03_model/scripts/evaluation/02_shap_analysis.py

# Phase 5: ì¶”ê°€ í‰ê°€ (Calibration, PR Curves, Risk Stratification)
python analysis_03_model/scripts/evaluation/03_additional_evaluation.py
```

## ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´

### ë³€ìˆ˜ ì„¤ëª… (12ê°œ)

| ë³€ìˆ˜ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| id | int | í™˜ì ê³ ìœ  ID |
| gender | object | ì„±ë³„ (Male, Female) |
| age | float | ë‚˜ì´ (0-82ì„¸) |
| hypertension | int | ê³ í˜ˆì•• ìœ ë¬´ (0/1) |
| heart_disease | int | ì‹¬ì¥ë³‘ ìœ ë¬´ (0/1) |
| ever_married | object | ê²°í˜¼ ì—¬ë¶€ (Yes/No) |
| work_type | object | ì§ì—… ìœ í˜• (Private, Self-employed, Govt_job ë“±) |
| Residence_type | object | ê±°ì£¼ ì§€ì—­ (Urban, Rural) |
| avg_glucose_level | float | í‰ê·  í˜ˆë‹¹ ìˆ˜ì¹˜ (mg/dL) |
| bmi | float | ì²´ì§ˆëŸ‰ì§€ìˆ˜ (kg/mÂ²) |
| smoking_status | object | í¡ì—° ìƒíƒœ (never smoked, formerly smoked, smokes, Unknown) |
| **stroke** | int | **ë‡Œì¡¸ì¤‘ ë°œìƒ ì—¬ë¶€ (0/1)** - Target ë³€ìˆ˜ |

### í´ë˜ìŠ¤ ë¶„í¬
- **Stroke=0 (ë¹„ë°œìƒ)**: 4,861ëª… (95.1%) âš ï¸ í´ë˜ìŠ¤ ë¶ˆê· í˜•
- **Stroke=1 (ë°œìƒ)**: 249ëª… (4.9%)

### ê²°ì¸¡ê°’
- **bmi**: 201ê°œ (3.9%) â†’ Median imputation ì²˜ë¦¬

## ğŸ¤– ëª¨ë¸ ë° í‰ê°€

### 7ê°€ì§€ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸

1. **Logistic Regression**
2. **Decision Tree**
3. **Random Forest**
4. **Support Vector Machine (SVM)**
5. **XGBoost**
6. **Gradient Boosting**
7. **Neural Network (MLP)**

### í‰ê°€ ê²°ê³¼

#### ê¸°ë³¸ ì„±ëŠ¥ í‰ê°€
- **Table 1**: Average Performance (AUC, CA, F1, Precision, Recall)
- **Table 2**: Performance by Class (Stroke=No vs Stroke=Yes)
- **Figure 3-4**: ROC Curves (Class 0 & Class 1)

#### ê³ ê¸‰ í‰ê°€
- **Calibration Analysis**: ëª¨ë¸ ë³´ì • ì„±ëŠ¥ (Brier Score)
- **Precision-Recall Curves**: ë¶ˆê· í˜• ë°ì´í„° ì„±ëŠ¥ í‰ê°€
- **Threshold Optimization**: Youden's Index ê¸°ë°˜ ìµœì  ì„ê³„ê°’
- **Risk Stratification**: Low/Medium/High ìœ„í—˜êµ° ë¶„ë¥˜

#### Feature Importance
- **Correlation Analysis**: Pearson correlation with stroke
- **SHAP Analysis**:
  - Importance plots (Random Forest, XGBoost, Gradient Boosting)
  - Summary plots (feature value distribution)
  - Dependence plots (top 6 features)

### í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
- **ë°©ë²•**: SMOTE (Synthetic Minority Over-sampling Technique)
- **ê²°ê³¼**: 1:19 â†’ 1:1 ë¹„ìœ¨ë¡œ ì¡°ì •

## ğŸ“ˆ ì£¼ìš” ê²°ê³¼

### ëª¨ë¸ ì„±ëŠ¥ (ì‹¤ì œ ê²°ê³¼)

| ëª¨ë¸ | AUROC | Accuracy | F1-Score | Precision | Recall |
|------|-------|----------|----------|-----------|--------|
| **Logistic Regression** | **0.8245** | 0.7877 | 0.5602 | 0.5643 | 0.7461 |
| Decision Tree | 0.8026 | 0.7847 | 0.5543 | 0.5565 | 0.7600 |
| Random Forest | 0.8088 | 0.7896 | 0.5656 | 0.5678 | 0.7600 |
| SVM | 0.8060 | 0.7896 | 0.5646 | 0.5668 | 0.7600 |
| XGBoost | 0.8165 | 0.7906 | 0.5682 | 0.5704 | 0.7600 |
| **Gradient Boosting** | 0.8133 | 0.7906 | **0.5676** | 0.5698 | 0.7600 |
| Neural Network | 0.8100 | 0.7877 | 0.5628 | 0.5651 | 0.7600 |

**ì£¼ìš” ë°œê²¬**:
- **Logistic Regression**: ê°€ì¥ ë†’ì€ AUROC (0.8245)
- **Gradient Boosting**: ìµœê³  calibration (Brier Score=0.0801)
- **Random Forest**: ê· í˜•ì¡íŒ ì„±ëŠ¥ (Sensitivity=0.84, Specificity=0.96)

### Feature Importance (SHAP)

**Top 5 ì¤‘ìš” ë³€ìˆ˜**:
1. **Age** (ë‚˜ì´) - ì••ë„ì  1ìœ„ (SHAP: 0.161-2.626)
2. **BMI** (ì²´ì§ˆëŸ‰ì§€ìˆ˜)
3. **Avg Glucose Level** (í‰ê·  í˜ˆë‹¹)
4. **Hypertension** (ê³ í˜ˆì••)
5. **Heart Disease** (ì‹¬ì¥ë³‘)

### Risk Stratification

| ìœ„í—˜êµ° | í™˜ì ë¹„ìœ¨ | ì‹¤ì œ ë‡Œì¡¸ì¤‘ ë°œìƒë¥  |
|--------|-----------|-------------------|
| Low Risk | 65.2% | **1.7%** |
| Medium Risk | 27.0% | **10.0%** |
| High Risk | 7.8% | **21.2%** |

## ğŸ“‚ ì¶œë ¥ íŒŒì¼

### ì „ì²˜ë¦¬ ê²°ê³¼
- `analysis_01_preprocess/data/final/stroke_preprocessed.csv` - ì „ì²˜ë¦¬ëœ ë°ì´í„°
- `analysis_01_preprocess/data/final/stroke_original.csv` - ì›ë³¸ ë°ì´í„°
- `analysis_01_preprocess/data/final/feature_names.txt` - Feature ëª©ë¡

### EDA ê²°ê³¼
- `analysis_02_eda/data/figures/correlation_heatmap.png` - ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
- `analysis_02_eda/data/figures/feature_distributions.png` - ë³€ìˆ˜ ë¶„í¬
- `analysis_02_eda/data/figures/categorical_analysis.png` - ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„ì„
- `analysis_02_eda/data/tables/*.csv` - í†µê³„ í…Œì´ë¸”

### ëª¨ë¸ ê²°ê³¼

- **Tables**:
  - `table1_average_performance.csv` - í‰ê·  ì„±ëŠ¥ ë©”íŠ¸ë¦­
  - `table2_class_performance.csv` - í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
  - `calibration_metrics.csv` - Calibration (Brier Score)
  - `optimal_thresholds.csv` - ìµœì  ì„ê³„ê°’ (Youden's Index)
  - `comprehensive_evaluation.csv` - ì¢…í•© í‰ê°€

- **Figures**:
  - `figure3_roc_curves_stroke_no.png` - Stroke=No ROC ê³¡ì„ 
  - `figure4_roc_curves_stroke_yes.png` - Stroke=Yes ROC ê³¡ì„ 
  - `confusion_matrices.png` - 7ê°œ ëª¨ë¸ Confusion Matrix
  - `calibration_curves.png` - Calibration ê³¡ì„ 
  - `precision_recall_curves.png` - Precision-Recall ê³¡ì„ 
  - `clinical_risk_stratification.png` - ìœ„í—˜êµ° ë¶„ë¥˜
  - `correlation_with_stroke.png` - Correlation ë¶„ì„
  - `shap_importance_*.png` - SHAP ì¤‘ìš”ë„ (3ê°œ ëª¨ë¸)
  - `shap_summary_*.png` - SHAP Summary (3ê°œ ëª¨ë¸)
  - `shap_dependence_*.png` - SHAP Dependence (3ê°œ ëª¨ë¸)

- **Models**:
  - `*.pkl` - í•™ìŠµëœ ëª¨ë¸ (7ê°œ)

### ë…¼ë¬¸ (Paper)
- **Sections**:
  - `01_background.md` - ì—°êµ¬ ë°°ê²½ ë° ëª©ì 
  - `02_methods.md` - ì—°êµ¬ ë°©ë²•ë¡ 
  - `03_results.md` - ì—°êµ¬ ê²°ê³¼ (14 figures)
  - `04_conclusions.md` - ê²°ë¡  ë° ê³ ì°°
- **Main Paper**:
  - `main_paper.md` - í†µí•© ë…¼ë¬¸ (~15,000 ë‹¨ì–´)

## âš™ï¸ ì„¤ì •

### ëœë¤ ì‹œë“œ
ì¬í˜„ì„±ì„ ìœ„í•´ `RANDOM_SEED = 42`ë¡œ ê³ ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

### Train/Test Split
- **Train**: 80%
- **Test**: 20%
- **Stratified Split**: í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€

### í•˜ì´í¼íŒŒë¼ë¯¸í„°
ê° ëª¨ë¸ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” `analysis_03_model/scripts/baseline/01_train_models.py`ì—ì„œ ìˆ˜ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ”§ ë¬¸ì œ í•´ê²°

### í•œê¸€ í°íŠ¸ ê¹¨ì§
```python
# Windows
plt.rcParams['font.family'] = 'Malgun Gothic'

# macOS
plt.rcParams['font.family'] = 'AppleGothic'

# Linux
plt.rcParams['font.family'] = 'NanumGothic'
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±
ë°ì´í„° í¬ê¸°ê°€ ì‘ì•„ ë¬¸ì œ ì—†ì§€ë§Œ, í•„ìš” ì‹œ ìƒ˜í”Œë§:
```python
df = pd.read_csv('dataset/stroke_dataset.csv', nrows=1000)
```

### íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì˜¤ë¥˜
```bash
# scikit-learn ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade scikit-learn

# imbalanced-learn ì„¤ì¹˜
pip install imbalanced-learn
```

## ğŸ“š ì°¸ê³  ìë£Œ

### ë°ì´í„° ì¶œì²˜
- Kaggle: Stroke Prediction Dataset
- https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset

### ê´€ë ¨ ë…¼ë¬¸
- SMOTE: Chawla et al. (2002) - Synthetic Minority Over-sampling Technique
- WHO Stroke Guidelines: https://www.who.int/news-room/fact-sheets/detail/stroke

## ğŸ‘¥ í”„ë¡œì íŠ¸ ì •ë³´

- **ì‘ì„±ì**: Data Science Team
- **ë‚ ì§œ**: 2025-11-24
- **ë²„ì „**: 1.0
- **Python**: â‰¥ 3.10

## âš ï¸ ì œí•œì‚¬í•­

1. **ë°ì´í„° í¬ê¸°**: 5,109ëª… (ì†Œê·œëª¨ ë°ì´í„°ì…‹)
2. **í´ë˜ìŠ¤ ë¶ˆê· í˜•**: Stroke=1 (4.9%) - SMOTEë¡œ ì²˜ë¦¬
3. **ê²°ì¸¡ê°’**: BMI 3.9% - Median imputation
4. **ì¼ë°˜í™”**: ë‹¨ì¼ ë°ì´í„°ì…‹ìœ¼ë¡œ ì™¸ë¶€ ê²€ì¦ í•„ìš”
5. **ì‹œê°„ ì •ë³´**: ë‹¨ì¼ ì‹œì  ë°ì´í„° (ì‹œê³„ì—´ ì•„ë‹˜)

## ğŸ“ ë¼ì´ì„¼ìŠ¤

ë³¸ í”„ë¡œì íŠ¸ëŠ” êµìœ¡ ë° ì—°êµ¬ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-11-24
